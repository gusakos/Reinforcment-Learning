{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gw12iq3e2i3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install and import the required libraries"
      ],
      "metadata": {
        "id": "rHrVUJDS2RVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rlcard\n",
        "import numpy as np\n",
        "from rlcard.games.limitholdem import Dealer\n",
        "from rlcard.games.base import Card\n",
        "import matplotlib.pyplot as plt\n",
        "from abc import ABC, abstractmethod\n",
        "from itertools import combinations, product, permutations\n",
        "from math import floor\n",
        "import time\n",
        "import sys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhthERhE2O3Z",
        "outputId": "0968a23b-8291-4b89-91bc-906a7a60a35e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rlcard\n",
            "  Downloading rlcard-1.2.0.tar.gz (269 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/269.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m245.8/269.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.0/269.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from rlcard) (1.22.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from rlcard) (2.3.0)\n",
            "Building wheels for collected packages: rlcard\n",
            "  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlcard: filename=rlcard-1.2.0-py3-none-any.whl size=325799 sha256=1b62c804511eb346655024fea8f1e5a32544e686bb85e5b19ef2f2435ad1819c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/39/26d73b035027276e526bec94b0217ed799109d7890c34a7d9b\n",
            "Successfully built rlcard\n",
            "Installing collected packages: rlcard\n",
            "Successfully installed rlcard-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declare some basic global variables"
      ],
      "metadata": {
        "id": "B_Ee5I3P2lwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHECK = 0\n",
        "BET = 1\n",
        "CALL = 2\n",
        "RAISE = 3\n",
        "FOLD = 4\n",
        "\n",
        "ANTE = 0.5"
      ],
      "metadata": {
        "id": "VfmJ_Bm_2qXF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declare some basic helper functions"
      ],
      "metadata": {
        "id": "HPcZxm_E2rs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_transition(round_no, player, action):\n",
        "    \"\"\"\n",
        "        Check whether the given action by the given player at the given round\n",
        "        incurs a transition (round change or game over).\n",
        "    \"\"\"\n",
        "\n",
        "    next_round = False\n",
        "\n",
        "    # round 1 ends when either agent calls or p2 checks\n",
        "\n",
        "    if (round_no==1 and (action==CALL or (player==2 and action==CHECK))):\n",
        "        next_round = True\n",
        "\n",
        "    # game is over when anyone folds\n",
        "\n",
        "    game_over = False\n",
        "    if action == FOLD:\n",
        "        game_over = True\n",
        "\n",
        "    if round_no == 2:\n",
        "        if (player==1 and action==CALL) or (player==2 and (action==CALL or action==CHECK)):\n",
        "            game_over = True\n",
        "\n",
        "    return next_round, game_over\n",
        "\n",
        "def action_name(action):\n",
        "    \"\"\"\n",
        "        Return the name of the action that corresponds to the given number.\n",
        "    \"\"\"\n",
        "\n",
        "    actions = [\n",
        "        \"Check\",\n",
        "        \"Bet\",\n",
        "        \"Call\",\n",
        "        \"Raise\",\n",
        "        \"Fold\",\n",
        "    ]\n",
        "\n",
        "    return actions[action]\n",
        "\n",
        "def init_deck(suits = ['S', 'H' , \"D\" , 'C'], ranks = ['T', 'J', 'Q' , 'K', 'A']):\n",
        "    \"\"\"\n",
        "        Create and return a deck consisting of cards of the given suits and ranks.\n",
        "\n",
        "        The length of the returned deck should be len(suits)*len(ranks).\n",
        "    \"\"\"\n",
        "\n",
        "    return [Card(suit,rank) for suit in suits for rank in ranks]\n",
        "\n",
        "def get_rank(rank):\n",
        "    if rank == '':\n",
        "        return -1\n",
        "    elif rank == \"T\":\n",
        "        return 1\n",
        "    elif rank == \"J\":\n",
        "        return 2\n",
        "    elif rank == \"Q\":\n",
        "        return 3\n",
        "    elif rank == \"K\":\n",
        "        return 4\n",
        "    elif rank == \"A\":\n",
        "        return 5\n",
        "    return 0\n",
        "\n",
        "def state_to_str(state):\n",
        "    \"\"\"\n",
        "        Convert a state to a printable str.\n",
        "    \"\"\"\n",
        "    cards = state[:3]\n",
        "    cards = tuple([str(x) if x is not None else \"_\" for x in cards])\n",
        "    return f\"state ({cards} {state[3:]})\""
      ],
      "metadata": {
        "id": "xsZHwgaz2xhZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Declare the functions that handle the creation of the environment and state space\n",
        "\n",
        "Those are the functions that calculate the permutations of the states and that characterize actions as legal or illegal in particular states"
      ],
      "metadata": {
        "id": "-SB8zc5G24ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_state_space(deck, private_cards, public_cards, other_fields, other_fields_legality, actions):\n",
        "    \"\"\"\n",
        "        Create a state space out of the given deck, with the given numbers of private\n",
        "        and public cards and with the rest of the fields concatenated to each state.\n",
        "\n",
        "        Should this return an iterator? The state space can be quite big, but also its a\n",
        "        bummer to only be able to access it through an iterator and not arbitrarily (by index),\n",
        "        so no.\n",
        "\n",
        "        Returns a list of tuples, each corresponding to a state.\n",
        "    \"\"\"\n",
        "\n",
        "    card_arrangements = generate_card_arrangements(deck, private_cards, public_cards)\n",
        "\n",
        "    other_fields_arrangements = list(product(*other_fields))\n",
        "\n",
        "    state_space = [state + field for state, field in product(card_arrangements, other_fields_arrangements)]\n",
        "\n",
        "    legality = {}\n",
        "\n",
        "    for state in state_space:\n",
        "\n",
        "        # each state gets the legality of the non-card fields in it\n",
        "        noncard_fields_state = state[-len(other_fields):]\n",
        "\n",
        "        legality.update({state: other_fields_legality[noncard_fields_state]})\n",
        "\n",
        "    return state_space, legality\n",
        "\n",
        "def generate_card_arrangements(deck, private_cards, public_cards):\n",
        "    \"\"\"\n",
        "        Generate and return all possible arrangements of the cards in the given deck, with\n",
        "        the given numbers of private cards (in the players hand) and public ones (on the\n",
        "        table). The only assumption being made is that all public cards are revealed at once\n",
        "        (they're either all known or all unknown).\n",
        "\n",
        "        Returns a list of tuples in each of which the first elements are the player's cards\n",
        "        and the rest are the public ones. Includes a state where the public ones are unknown.\n",
        "    \"\"\"\n",
        "\n",
        "    arrangements = []\n",
        "\n",
        "    # for each first card (this can be more generalized as combinations of cards in deck by #cards in hand)\n",
        "    for cards in combinations(deck, private_cards):\n",
        "\n",
        "        # remove it from the deck\n",
        "        other_cards = list(set(deck) - set(cards))\n",
        "\n",
        "        # generate the possible combinations of the rest (the 2 here is the number of public cards)\n",
        "        rest_combinations = list(permutations(other_cards, public_cards))\n",
        "\n",
        "        # add the empty combination\n",
        "        rest_combinations += [tuple([None]*public_cards)]\n",
        "\n",
        "        # combine the combinations with the card\n",
        "        for arrangement in rest_combinations:\n",
        "            arrangements.append(tuple([card for card in cards]) + (arrangement))\n",
        "\n",
        "    return arrangements\n",
        "\n",
        "def create_default_env():\n",
        "    \"\"\"\n",
        "        Creates and returns the default environment:\n",
        "            - available actions\n",
        "            - cards from 10 to A, all suits\n",
        "            - state space has the following fields (plus public and private cards):\n",
        "                - player ID (max 2)\n",
        "                - round #   (max 2)\n",
        "                - own chips (max 4)\n",
        "                - opp chips (max 4)\n",
        "\n",
        "        Also creates and returns a state-action legality dict that can be used\n",
        "        to derive the complete one when compiling the complete state space.\n",
        "\n",
        "        Basically provides everything necessary to create an environment, so we\n",
        "        can proceed in an environment-agnostic way and compile the complete\n",
        "        state space and legality dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    # 0) available actions\n",
        "    actions = range(5)\n",
        "\n",
        "    # 1) card suits and ranks\n",
        "    suits = ['S', 'H' , \"D\" , 'C']\n",
        "    ranks = ['T', 'J', 'Q' , 'K', 'A']\n",
        "\n",
        "    # 2) state space fields beside cards\n",
        "    player_ids = [1, 2]\n",
        "    rounds = [1, 2]\n",
        "    own_chips = list(range(5))\n",
        "    opp_chips = list(range(5))\n",
        "    fields = [\n",
        "        player_ids,\n",
        "        rounds,\n",
        "        own_chips,\n",
        "        opp_chips\n",
        "    ]\n",
        "    player_id_i = 0\n",
        "    round_i = 1\n",
        "    own_chips_i = 2\n",
        "    opp_chips_i = 3\n",
        "\n",
        "    # 3) combinations of other fields\n",
        "    other_fields_arrangements = list(product(*fields))\n",
        "\n",
        "    # 4) state-action legality (besides cards - cards don't matter as far as legality is concerned)\n",
        "    other_fields_legality = {state: {action: False for action in actions} for state in other_fields_arrangements}\n",
        "\n",
        "    for state, actions in other_fields_legality.items():\n",
        "\n",
        "        # there are differenct legal actions for player 1 and player 2\n",
        "        if state[player_id_i] == 1:\n",
        "\n",
        "            # the state of the game is reflected on the # of chips each player has bet\n",
        "            if state[own_chips_i] == state[opp_chips_i]:        # then its our move and we check/bet\n",
        "                actions.update({CHECK: True})\n",
        "                actions.update({BET: True})\n",
        "            elif state[own_chips_i] < state[opp_chips_i]:       # then we're replying to a bet or a raise\n",
        "                actions.update({CALL: True})\n",
        "                actions.update({FOLD: True})\n",
        "\n",
        "        elif state[player_id_i] == 2:\n",
        "\n",
        "            # the state of the game is reflected on the # of chips each player has bet\n",
        "            if state[own_chips_i] == state[opp_chips_i]:        # then its our move and we check/bet\n",
        "                actions.update({CHECK: True})\n",
        "                actions.update({BET: True})\n",
        "            elif state[own_chips_i] < state[opp_chips_i]:       # then we're replying to a bet\n",
        "                actions.update({CALL: True})\n",
        "                actions.update({FOLD: True})\n",
        "                actions.update({RAISE: True})\n",
        "\n",
        "        else:\n",
        "            # error\n",
        "            print(f\"There is an error in state {state}! player id '{state[player_id_i]} is invalid\")\n",
        "\n",
        "        other_fields_legality.update({state: actions})\n",
        "\n",
        "    return suits, ranks, fields, other_fields_arrangements, player_id_i, round_i, own_chips_i, opp_chips_i, other_fields_legality, actions\n",
        "\n",
        "def print_state_space_and_legality(state_space, legality):\n",
        "    \"\"\"\n",
        "        Print the state space and the legal actions for every state.\n",
        "\n",
        "        Used for debugging.\n",
        "    \"\"\"\n",
        "\n",
        "    for state in state_space:\n",
        "        cards = state[:3]\n",
        "        cards = tuple([str(x) for x in cards])\n",
        "        #print(f\"state ({cards} {state[3:]}), legal actions: {[action_name(action) for action, legal in legality[state].items() if legal]}\")\n",
        "        print(f\"state ({cards} {state[3:]}), legal actions: {legality[state].items()}\")"
      ],
      "metadata": {
        "id": "5QSxTbsF3Xf6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Declare the basic parts of the environment\n",
        "The dealer and the judger (the class implementing the logic for deriving the winner and distributing the pot at the end of each game)"
      ],
      "metadata": {
        "id": "7nJuuEow3YWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2wgdz9DC2HeV"
      },
      "outputs": [],
      "source": [
        "class Dealer:\n",
        "    \"\"\"\n",
        "        Dealer initializes a deck given by init_deck\n",
        "        shufles the the deck aka randomizes the cards order\n",
        "        deals a card , gives the last card in deck\n",
        "\n",
        "        Returns:\n",
        "        card\n",
        "    \"\"\"\n",
        "    def __init__(self, np_random, suits = ['S', 'H' , \"D\" , 'C'], ranks = ['T', 'J', 'Q' , 'K', 'A'], deck=None):\n",
        "        self.np_random = np_random\n",
        "        self.deck = init_deck(suits, ranks) if deck is None else deck\n",
        "        self.shuffle()\n",
        "        self.pot = 0\n",
        "\n",
        "    def reset(self, suits = ['S', 'H' , \"D\" , 'C'], ranks = ['T', 'J', 'Q' , 'K', 'A'], deck=None):\n",
        "        self.deck = init_deck(suits, ranks) if deck is None else deck\n",
        "        self.shuffle()\n",
        "\n",
        "    def shuffle(self):\n",
        "        self.np_random.shuffle(self.deck)\n",
        "\n",
        "    def deal_card(self):\n",
        "        return self.deck.pop()\n",
        "\n",
        "class Judger:\n",
        "    ''' The Judger class which deciedes the winner between 2 players given their cards and the public  too\n",
        "        Returns a list of the chips won or lost for every player\n",
        "    '''\n",
        "    def __init__(self, np_random):\n",
        "        ''' Initialize a judger class\n",
        "        '''\n",
        "        self.np_random = np_random\n",
        "\n",
        "    @staticmethod\n",
        "    def judge_game(players, public_cards):\n",
        "        ''' Judge the winner of the game.\n",
        "\n",
        "        Args:\n",
        "            players (list): The list of players who play the game\n",
        "            public_card (object): The public card that seen by all the players\n",
        "\n",
        "        Returns:\n",
        "            (list): Each entry of the list corresponds to one entry of the\n",
        "        '''\n",
        "        # Judge who are the winners\n",
        "        winners = [0] * len(players)\n",
        "        fold_count = 0\n",
        "        ranks_list = []\n",
        "\n",
        "        #save ranks of the 2 players in ranks list\n",
        "        for player in players:\n",
        "            ranks_list.append(get_rank(player.hand.rank))\n",
        "\n",
        "\n",
        "         #keep track of the max rank between the 2 players\n",
        "        max_rank = max(ranks_list)\n",
        "\n",
        "        # First check if anyone has folded then the other wins\n",
        "        if players[0].status== 'folded':\n",
        "            winners[1]= 1\n",
        "        if players[1].status== 'folded':\n",
        "            winners[0]= 1\n",
        "\n",
        "\n",
        "        # If any of the players matches both public cards wins. Both the 2 players can win and pot is splitted\n",
        "        if sum(winners) < 1:\n",
        "            for idx, player in enumerate(players):\n",
        "                if player.hand.rank == public_cards[0].rank and player.hand.rank == public_cards[1].rank:\n",
        "                    winners[idx] = 1\n",
        "\n",
        "        # If one of the players matches one public cards wins. if both  then check the higher rank , again both can win\n",
        "        if sum(winners) < 1:\n",
        "            #Both have one pair\n",
        "            if (players[0].hand.rank == public_cards[0].rank or players[0].hand.rank == public_cards[1].rank) and (players[1].hand.rank == public_cards[0].rank or players[1].hand.rank == public_cards[1].rank):\n",
        "\n",
        "                #check the rank\n",
        "                for idx, player in enumerate(players):\n",
        "                    if get_rank(player.hand.rank) == max_rank:\n",
        "                        winners[idx] = 1\n",
        "\n",
        "\n",
        "            #Only one has a pair\n",
        "            else:\n",
        "                for idx, player in enumerate(players):\n",
        "                    if player.hand.rank == public_cards[0].rank or player.hand.rank == public_cards[1].rank:\n",
        "                        winners[idx] = 1\n",
        "\n",
        "        # If non of the above conditions, the winner player is the one with the highest card rank\n",
        "        if sum(winners) < 1:\n",
        "            max_index = [i for i, j in enumerate(ranks_list) if j == max_rank]\n",
        "            for idx in max_index:\n",
        "                winners[idx] = 1\n",
        "\n",
        "        if sum(winners) < 1:\n",
        "            print('ERROR on judging')\n",
        "        # Compute the total chips\n",
        "        total = 0\n",
        "        for p in players:\n",
        "            total += p.in_chips\n",
        "\n",
        "        # split the winnings in case there are 2 winners\n",
        "        each_win = float(total) / sum(winners)\n",
        "        payoffs = []\n",
        "\n",
        "        # Check every player's winning state and give him the credit\n",
        "        for i, _ in enumerate(players):\n",
        "            # winner\n",
        "            if winners[i] == 1:\n",
        "                #if player is a winner give him wiining_chips- contributed_chips so  he gets the clear profit\n",
        "                payoffs.append(each_win - players[i].in_chips)\n",
        "            # losser\n",
        "            else:\n",
        "                #if player is a losser give him -his contributed_chips\n",
        "                payoffs.append(float(-players[i].in_chips))\n",
        "\n",
        "        #print(f\"\\tpayoffs are {payoffs}\")\n",
        "\n",
        "        return payoffs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Declare the basic types of opponents that the Q-Learning algorithm will train with and face in games\n",
        "\n",
        "A random agent that chooses one of the legal actions by chance in every state\n",
        "\n",
        "A threshold agent that bets or raises if its cards satisfy some conditions\n",
        "\n",
        "An abstract base class (that ended up only being a base for one class) is also defined here"
      ],
      "metadata": {
        "id": "7fSQ-d7v35Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAgent():\n",
        "    \"\"\"\n",
        "    Random agent implitation\n",
        "    The action of the agent is decided by a random value\n",
        "\n",
        "    Dont forgret that an agent is a player too.\n",
        "\"\"\"\n",
        "\n",
        "    def __init__(self,ID):\n",
        "        ''' Initilize the random agent\n",
        "\n",
        "        Args:\n",
        "            num_actions (int): The size of the ouput action space\n",
        "        '''\n",
        "        self.ID = ID\n",
        "        #playe's status\n",
        "        self.status = 'alive'\n",
        "\n",
        "        self.type= 'Random'\n",
        "\n",
        "        #player's hand\n",
        "        self.hand = None\n",
        "        # The chips that this player has put in until now\n",
        "        self.in_chips = 0\n",
        "\n",
        "        self.all_chips= 0\n",
        "\n",
        "        # self.player_id = player_id\n",
        "    \"\"\"\n",
        "    Action of the agent given the state he is in\n",
        "    \"\"\"\n",
        "    def step(self, available_actions):\n",
        "        \"\"\"\n",
        "            Decide the action of the agent given the state\n",
        "        \"\"\"\n",
        "\n",
        "        index = np.random.choice(len(available_actions))\n",
        "        return available_actions[index]\n",
        "\n",
        "class ThresholdAgent():\n",
        "    \"\"\"\n",
        "    Threshold agent implitation\n",
        "\n",
        "    The action of the agent is decided by by the rank of his card\n",
        "    He basically plays aggressively  at first round with high values of 'K' and 'A' betting or raisinig , callin with Q and folding with '10' and 'J'\n",
        "    For second round he raises or bets with one pair at least and folds  or checks every other time\n",
        "\n",
        "\n",
        "    Dont forgret that an agent is a player too.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,ID):\n",
        "        ''' Initilize the random agent\n",
        "\n",
        "        Args:\n",
        "            num_actions (int): The size of the ouput action space\n",
        "        '''\n",
        "        self.ID=ID\n",
        "        #playe's status\n",
        "        self.status = 'alive'\n",
        "\n",
        "        self.type= 'Threshold'\n",
        "\n",
        "        #player's hand\n",
        "        self.hand = None\n",
        "        # The chips that this player has put in until now\n",
        "        self.in_chips = 0\n",
        "\n",
        "        self.all_chips= 0\n",
        "\n",
        "        # self.player_id = player_id\n",
        "    \"\"\"\n",
        "    Action of the agent given the state he is in\n",
        "    \"\"\"\n",
        "\n",
        "    def step(self,available_actions, round_no, public_cards):\n",
        "        \"\"\"\n",
        "            Decide the action of the agent given the state and the public_cards and playe's hand\n",
        "            threshold players bet or raises with K and A in the first round and with a pair in the second one.\n",
        "        \"\"\"\n",
        "\n",
        "        hand=self.hand\n",
        "\n",
        "        if round_no == 1:\n",
        "            if hand.rank in [\"K\", \"A\"]:\n",
        "                if RAISE in available_actions:\n",
        "                    action = RAISE\n",
        "                elif BET in available_actions:\n",
        "                    action = BET\n",
        "                elif CALL in available_actions:\n",
        "                    action = CALL\n",
        "                elif CHECK in available_actions:\n",
        "                    action = CHECK\n",
        "                elif FOLD in available_actions:\n",
        "                    action = FOLD\n",
        "                else:\n",
        "                    print(f\"Error! Threshold agent at round {round_no}, hand {str(hand)} and public cards {[str(x) for x in public_cards]} with no valid actions (available actions: {available_actions})\")\n",
        "            else:\n",
        "                if CALL in available_actions:\n",
        "                    action = CALL\n",
        "                elif CHECK in available_actions:\n",
        "                    action = CHECK\n",
        "                elif FOLD in available_actions:\n",
        "                    action = FOLD\n",
        "                else:\n",
        "                    print(f\"Error! Threshold agent at round {round_no}, hand {str(hand)} and public cards {[str(x) for x in public_cards]} with no valid actions (available actions: {available_actions})\")\n",
        "        elif round_no == 2:\n",
        "            if hand.rank in [card.rank for card in self.public_cards]:\n",
        "                if RAISE in available_actions:\n",
        "                    action = RAISE\n",
        "                elif BET in available_actions:\n",
        "                    action = BET\n",
        "                elif CALL in available_actions:\n",
        "                    action = CALL\n",
        "                elif CHECK in available_actions:\n",
        "                    action = CHECK\n",
        "                elif FOLD in available_actions:\n",
        "                    action = FOLD\n",
        "                else:\n",
        "                    print(f\"Error! Threshold agent at round {round_no}, hand {str(hand)} and public cards {[str(x) for x in public_cards]} with no valid actions (available actions: {available_actions})\")\n",
        "            else:\n",
        "                if CALL in available_actions:\n",
        "                    action = CALL\n",
        "                if CHECK in available_actions:\n",
        "                    action = CHECK\n",
        "                elif FOLD in available_actions:\n",
        "                    action = FOLD\n",
        "                else:\n",
        "                    print(f\"Error! Threshold agent at round {round_no}, hand {str(hand)} and public cards {[str(x) for x in public_cards]} with no valid actions (available actions: {available_actions})\")\n",
        "        else:\n",
        "            print(f\"Invalid round number {round_no}!\")\n",
        "\n",
        "        return action\n",
        "\n",
        "class BaseAgent(ABC):\n",
        "    \"\"\"\n",
        "        Abstract Base Class (ABC) for agents that can interact with the environment.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, id, state_space, action_space):\n",
        "        self.ID = id\n",
        "        self.type= None\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.all_chips= 0\n",
        "        self.policy = None\n",
        "        self.state = None\n",
        "\n",
        "        self.hand = None\n",
        "        self.in_chips = 0\n",
        "        self.status = 'alive'\n",
        "\n",
        "    @abstractmethod\n",
        "    def step(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "T9i2sRCi2Ij3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define the environment in which the Q-Learning agent will train and play"
      ],
      "metadata": {
        "id": "JavnToWn4P4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QEnv():\n",
        "    \"\"\"\n",
        "        An environment for the implementation of the Q learning algorithm.\n",
        "\n",
        "        Does not need to be separate however i got dizzy trying to read the other one.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, suits, ranks, non_card_state_fields, non_card_fields_legality, actions, player_id_i, round_i, own_chips_i, opp_chips_i):\n",
        "        \"\"\"\n",
        "            Initialize a the environment:\n",
        "                - max rounds\n",
        "                - suits & ranks\n",
        "                - sate space\n",
        "                - action space\n",
        "                - state-action legality\n",
        "                - dealer\n",
        "                - judger\n",
        "                - agents\n",
        "                - trainer opponent state\n",
        "        \"\"\"\n",
        "\n",
        "        self.max_rounds = 2\n",
        "        self.suits = suits\n",
        "        self.ranks = ranks\n",
        "        self.deck = init_deck(self.suits, self.ranks)\n",
        "        self.state_space, self.legality = make_state_space(\n",
        "            self.deck,\n",
        "            private_cards=1,\n",
        "            public_cards=2,\n",
        "            other_fields=non_card_state_fields,\n",
        "            other_fields_legality=non_card_fields_legality,\n",
        "            actions=actions\n",
        "        )\n",
        "        self.actions = actions\n",
        "        self.agents:list[QLearningAgent] = [None, None]\n",
        "\n",
        "        # initialize an RNG for the dealer (and the judger...?)\n",
        "        self.rng = np.random.RandomState()\n",
        "        self.dealer = Dealer(self.rng, deck=self.deck)\n",
        "        self.judger = Judger(self.rng)  # why does the judger need an RNG?\n",
        "\n",
        "        # initialize state space controls\n",
        "        self.player_id_i = player_id_i\n",
        "        self.round_i = round_i\n",
        "        self.own_chips_i = own_chips_i\n",
        "        self.opp_chips_i = opp_chips_i\n",
        "\n",
        "        self.state = None\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            Reset the state space. Resets:\n",
        "                - deck\n",
        "                - dealer\n",
        "                - public and private cards\n",
        "                - chips bet\n",
        "                - round_no\n",
        "                - trainer opponent state\n",
        "        \"\"\"\n",
        "\n",
        "        self.dealer.reset()\n",
        "        self.round_no = 1\n",
        "        self.public_cards = [None, None]\n",
        "        self.hands = [None, None]\n",
        "        self.chips_in = [0, 0]\n",
        "        self.state = None\n",
        "\n",
        "    def new_game(self, requesting_player, agent1, agent2, v=False):\n",
        "        \"\"\"\n",
        "            Create a new game setting, set the internal variables accordingly and return\n",
        "            the initial state of the requesting player.\n",
        "        \"\"\"\n",
        "\n",
        "        # requesting player index\n",
        "        _p = requesting_player-1\n",
        "\n",
        "        # set up the new game\n",
        "        self.reset()\n",
        "        self.public_cards = [self.dealer.deal_card() for i in range(2)]\n",
        "        self.hands = [self.dealer.deal_card() for i in range(2)]\n",
        "        self.chips_in = [0, 0]\n",
        "\n",
        "        # create the state of the requesting player\n",
        "        req_state = (\n",
        "            self.hands[_p],\n",
        "            None, None,\n",
        "            _p + 1,\n",
        "            self.round_no,\n",
        "            self.chips_in[_p],\n",
        "            self.chips_in[not _p],\n",
        "        )\n",
        "\n",
        "        # create the state of the opponent that will be incorporated in the environment\n",
        "        self.state = (\n",
        "            self.hands[not _p],\n",
        "            None, None,\n",
        "            (not _p) + 1,\n",
        "            self.round_no,\n",
        "            self.chips_in[not _p],\n",
        "            self.chips_in[_p],\n",
        "        )\n",
        "\n",
        "        self.agents = [agent1, agent2]\n",
        "        self.agents[0].hand = self.hands[0]\n",
        "        self.agents[1].hand = self.hands[1]\n",
        "        for agent in self.agents:\n",
        "            agent.in_chips = 0\n",
        "            agent.status=\"alive\"\n",
        "\n",
        "        if v:\n",
        "            print(\"=\"*70)\n",
        "            print(\"New game created!\")\n",
        "            print(f\"agent state: {state_to_str(req_state)}, bet: \")\n",
        "            print(f\"env state: {state_to_str(self.state)}\")\n",
        "            print(f\"public cards (not shown yet): {[str(x) for x in self.public_cards]}\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        # if the new game was created by player 2, then let the opponent play a round first\n",
        "        if requesting_player == 2:\n",
        "            print(f\"game requested by player 2\")\n",
        "            available_actions = [action for action in self.actions if self.is_legal(action, self.state)]\n",
        "            trainer_action = None\n",
        "            if isinstance(agent2, ThresholdAgent):\n",
        "                if self.round_no == 1:\n",
        "                    if self.hands[not _p].rank in [\"K\", \"A\"]:\n",
        "                        if RAISE in available_actions:\n",
        "                            trainer_action = RAISE\n",
        "                        elif BET in available_actions:\n",
        "                            trainer_action = BET\n",
        "                        elif CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        elif CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no valid actions (available actions: {available_actions})\")\n",
        "                    else:\n",
        "                        if CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        elif CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no check or fold action available (available actions: {available_actions})\")\n",
        "                elif self.round_no == 2:\n",
        "                    if self.hands[not _p].rank in [card.rank for card in self.public_cards]:\n",
        "                        if RAISE in available_actions:\n",
        "                            trainer_action = RAISE\n",
        "                        elif BET in available_actions:\n",
        "                            trainer_action = BET\n",
        "                        elif CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        elif CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no valid actions (available actions: {available_actions})\")\n",
        "                    else:\n",
        "                        if CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        if CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no check/fold action (available actions: {available_actions})\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"Invalid round number {self.round_no}!\")\n",
        "            else:\n",
        "                if len(available_actions) == 0:\n",
        "                    print(f\"No available actions at {state_to_str(self.state)}\")\n",
        "                    print(f\"{self.legality[self.state]}\")\n",
        "                trainer_action = np.random.choice(available_actions)\n",
        "\n",
        "            # perform the trainer action\n",
        "            rewards, self.state, game_over = self.perform_action((not _p)+1, trainer_action, trainer=True)\n",
        "\n",
        "            req_state = [self.hands[_p]]\n",
        "\n",
        "            if self.round_no == 2:\n",
        "                req_state.append(self.public_cards[0])\n",
        "                req_state.append(self.public_cards[1])\n",
        "            else:\n",
        "                req_state.append(None)\n",
        "                req_state.append(None)\n",
        "\n",
        "            req_state.append(requesting_player)\n",
        "            req_state.append(self.round_no)\n",
        "            req_state.append(floor(self.chips_in[_p]))\n",
        "            req_state.append(floor(self.chips_in[not _p]))\n",
        "            req_state = tuple(req_state)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return req_state\n",
        "\n",
        "    def is_legal(self, action, state):\n",
        "        \"\"\"\n",
        "            Can you do the particular action when in that particular space?\n",
        "\n",
        "            Returns a boolean.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            #print(f\"self.legality[state] is {self.legality[state]}\")\n",
        "            result = self.legality[state][action]\n",
        "        except KeyError:    # if no such action in the legal list of the given state, then\n",
        "            result = False\n",
        "\n",
        "        #print(f\"checking legality of action {action_name(action)} ({action}) at state {state_to_str(state)}: {'allowed' if result else 'illegal'}\\t\\t(legality: {self.legality[state]})\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def perform_action(self, player, action, trainer=False, threshhold=False):\n",
        "        \"\"\"\n",
        "            Perform the requested action on account of the specified player.\n",
        "\n",
        "            In order to go to the next state, the opponent will have to make a move.\n",
        "            The policy of that oponent is either a threshold one or a random one,\n",
        "            controlled by the corresponding argument.\n",
        "                - The threshold policy is to only bet/raise in the following scenarios:\n",
        "                    - with a K or 1 in round 1\n",
        "                    - with any pair in round 2\n",
        "                  and check/fold in any other case\n",
        "                - The random policy is to pick a (legal) action at random every time\n",
        "\n",
        "            Returns the next state, the reward and whether or not the new state is a terminating one\n",
        "            in a 3-tuple.\n",
        "        \"\"\"\n",
        "\n",
        "        # check whether we should progress to the next round or end the game\n",
        "        next_round, game_over = check_transition(self.round_no, player, action)\n",
        "\n",
        "        _p = player-1   # the player ID as an index\n",
        "\n",
        "        # add the players card to the new state\n",
        "        new_state = [self.hands[_p]]\n",
        "\n",
        "        # 1) take care of the pot\n",
        "        if action == CHECK or action == FOLD:\n",
        "            pass    # nothing changes as far as the pot is concerned\n",
        "        elif action == BET:\n",
        "            self.chips_in[_p] += 1  # +1 chip to the player\n",
        "        elif action == RAISE:\n",
        "            self.chips_in[_p] += 2  # +2 chip to the player\n",
        "        elif action == CALL:\n",
        "            self.chips_in[_p] = self.chips_in[not _p]   # player's chips match those of the opp\n",
        "        else:\n",
        "            print(f\"Unknown action '{action}'\")\n",
        "            return None\n",
        "\n",
        "        # 2) take care of the player's status\n",
        "        if action == FOLD:\n",
        "            self.agents[_p].status = 'folded'\n",
        "\n",
        "        # 3) increment the round if needed\n",
        "        if next_round:\n",
        "            if self.round_no == 1:\n",
        "\n",
        "                self.round_no += 1\n",
        "\n",
        "                # show the public cards to the players\n",
        "                for j in range(2):  # hardcoded 2 because we dont store number of public cards in the env\n",
        "                    new_state.append(self.public_cards[j])\n",
        "\n",
        "                    #agent.state[1+j] = self.public_cards[j] # hardcoded 1 because we dont store number of private cards in env\n",
        "            else:\n",
        "                print(\"Error! Indication that the round should increment while at round 2\")\n",
        "        else:\n",
        "            # keep on not showing the cards to the player\n",
        "            new_state.append(None)\n",
        "            new_state.append(None)\n",
        "\n",
        "        # 5) check if the game is over and calculate rewards\n",
        "        rewards = [0, 0]\n",
        "        if game_over:\n",
        "\n",
        "            # add the antes to each player's bets\n",
        "            self.chips_in = [i+ANTE for i in self.chips_in]\n",
        "            for i, agent in enumerate(self.agents):\n",
        "                agent.in_chips = self.chips_in[i]\n",
        "\n",
        "            payoffs = self.judger.judge_game(self.agents, self.public_cards)\n",
        "            rewards = payoffs\n",
        "            new_state.append(_p + 1)\n",
        "            new_state.append(self.round_no)\n",
        "            new_state.append(floor(self.chips_in[_p]))\n",
        "            new_state.append(floor(self.chips_in[not _p]))\n",
        "            #print(f\"Result: player 1 gets {rewards[0]} chips, player 2 gets {rewards[1]} chips\")\n",
        "            return rewards, tuple(new_state), True\n",
        "\n",
        "        # now do what the opponent would do\n",
        "        self.state = [x for x in self.state[:3]]\n",
        "        self.state.append((not _p)+1)\n",
        "        self.state.append(self.round_no)\n",
        "        self.state.append(self.chips_in[not _p])\n",
        "        self.state.append(self.chips_in[_p])\n",
        "        self.state = tuple(self.state)\n",
        "        #print(f\"the action of the agent put the environment in the state {state_to_str(self.state)}\")\n",
        "\n",
        "        if not trainer:\n",
        "            available_actions = [action for action in self.actions if self.is_legal(action, self.state)]\n",
        "            trainer_action = None\n",
        "            if threshhold:\n",
        "                if self.round_no == 1:\n",
        "                    if self.hands[not _p].rank in [\"K\", \"A\"]:\n",
        "                        if RAISE in available_actions:\n",
        "                            trainer_action = RAISE\n",
        "                        elif BET in available_actions:\n",
        "                            trainer_action = BET\n",
        "                        elif CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        elif CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no valid actions (available actions: {available_actions})\")\n",
        "                    else:\n",
        "                        if CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        elif CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no check or fold action available (available actions: {available_actions})\")\n",
        "                elif self.round_no == 2:\n",
        "                    if self.hands[not _p].rank in [card.rank for card in self.public_cards]:\n",
        "                        if RAISE in available_actions:\n",
        "                            trainer_action = RAISE\n",
        "                        elif BET in available_actions:\n",
        "                            trainer_action = BET\n",
        "                        elif CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        elif CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no valid actions (available actions: {available_actions})\")\n",
        "                    else:\n",
        "                        if CALL in available_actions:\n",
        "                            trainer_action = CALL\n",
        "                        if CHECK in available_actions:\n",
        "                            trainer_action = CHECK\n",
        "                        elif FOLD in available_actions:\n",
        "                            trainer_action = FOLD\n",
        "                        else:\n",
        "                            print(f\"Error! In state {self.state} with no check/fold action (available actions: {available_actions})\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"Invalid round number {self.round_no}!\")\n",
        "\n",
        "            else:\n",
        "                if len(available_actions) == 0:\n",
        "                    print(f\"No available actions at {state_to_str(self.state)}\")\n",
        "                    print(f\"{self.legality[self.state]}\")\n",
        "                trainer_action = np.random.choice(available_actions)\n",
        "\n",
        "            # perform the trainer action\n",
        "            #print(f\"({'threshold' if threshhold else 'random'}) trainer is at state {state_to_str(self.state)} and {action_name(trainer_action)}s (out of {[action_name(x) for x in available_actions]})\")\n",
        "            rewards, self.state, game_over = self.perform_action((not _p)+1, trainer_action, trainer=True)\n",
        "\n",
        "            new_state = [self.hands[_p]]\n",
        "\n",
        "            if self.round_no == 2:\n",
        "                new_state.append(self.public_cards[0])\n",
        "                new_state.append(self.public_cards[1])\n",
        "            else:\n",
        "                new_state.append(None)\n",
        "                new_state.append(None)\n",
        "\n",
        "            new_state.append(player)\n",
        "            new_state.append(self.round_no)\n",
        "            new_state.append(floor(self.chips_in[_p]))\n",
        "            new_state.append(floor(self.chips_in[not _p]))\n",
        "            new_state = tuple(new_state)\n",
        "\n",
        "\n",
        "\n",
        "        return rewards, new_state, game_over"
      ],
      "metadata": {
        "id": "LOF-5OX04Pq9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define the Q-Learning agent"
      ],
      "metadata": {
        "id": "5FEchCmZ4lrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "        An agent that implements the Q Learning algorithm to figure out how to play optimally.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, id, env:QEnv, learning_rate, discount_factor):\n",
        "        \"\"\"\n",
        "            Construct a new Q Learning agent with the given ID, state & action space.\n",
        "\n",
        "            The is_legal argument is required to construct the Q table (we will only have entries\n",
        "            for actions that are legal in each state). It should be provided as part of the\n",
        "            environment.\n",
        "        \"\"\"\n",
        "        super().__init__(id, env.state_space, env.actions)\n",
        "        self.type = \"Q_agent\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.Q = {state: {action:0 for action in env.actions if env.is_legal(action, state)} for state in env.state_space}\n",
        "\n",
        "    def e_greedy_policy(self, state, epsilon):\n",
        "        \"\"\"\n",
        "            Return an action for the given state according to an ε-greedy policy on the current\n",
        "            Q table.\n",
        "\n",
        "            There is no need to derive an explicit e_greedy_policy because:\n",
        "                a) the value of epsilon changes over time so the probabilities would not be the same\n",
        "                b) supposedly the Q table is (even a little bit) different each time this is called,\n",
        "                   so the policy is not static\n",
        "\n",
        "            To be used while training.\n",
        "        \"\"\"\n",
        "\n",
        "        # perform an experiment that succeeds with prob. epsilon_t\n",
        "        random = np.random.rand() < epsilon\n",
        "\n",
        "        # depending on the outcome of the experiment, pick an index and return it\n",
        "        if random:\n",
        "            return np.random.choice(list(self.Q[state].keys()))\n",
        "        else:\n",
        "            return list(self.Q[state].keys())[np.argmax(list(self.Q[state].values()))]\n",
        "\n",
        "    def derive_greedy_policy(self):\n",
        "        \"\"\"\n",
        "            Derive a greedy policy from the current Q table.\n",
        "\n",
        "            To be used in the evaluation stage to avoid repeatedly querying the Q table and calculating\n",
        "            argmax's.\n",
        "        \"\"\"\n",
        "\n",
        "        policy = {}\n",
        "\n",
        "        # iterate over the states in the Q table\n",
        "        for state, actions in self.Q.items():\n",
        "\n",
        "            if len(actions.values()) == 0:\n",
        "                policy.update(\n",
        "                    {state: None} # should raise an error if we end up in such a state\n",
        "                )\n",
        "            else:\n",
        "                policy.update(\n",
        "                    {\n",
        "                        # select the action with the maximum value and add it to the policy\n",
        "                        state: (list(actions.keys())[np.argmax(list(actions.values()))])    # why is this a tuple?\n",
        "                    }\n",
        "                )\n",
        "\n",
        "        return policy\n",
        "\n",
        "    def train(self, num_episodes, env:QEnv,  opp_agent, max_epsilon = 1.0, min_epsilon = 0.05, decay_rate = 0.0005, fixed_learning_rate=True, learning_rate=0.01, min_learning_rate=1, max_learning_rate=0.01, learning_rate_decay_rate=0.005, threshhold_trainer=False):\n",
        "        \"\"\"\n",
        "            Run the specified number of training episodes, changing the Q table (which also implies\n",
        "            a policy). While training\n",
        "\n",
        "            For the time being we can only train with e_greedy as a training policy.\n",
        "\n",
        "            This does not return anything, it only changes the values of the Q table.\n",
        "        \"\"\"\n",
        "\n",
        "        self.rewards = []\n",
        "        self.cumulative_reward = []\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "\n",
        "            print(f\"\\rRunning training episode {episode}\", end=\"\")\n",
        "\n",
        "            # calculate the epsilon for the current episode\n",
        "            epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "            if fixed_learning_rate:\n",
        "                learning_rate = learning_rate\n",
        "            else:\n",
        "                learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate)*np.exp(-learning_rate_decay_rate*episode)\n",
        "\n",
        "            # in each episode draw some cards at random\n",
        "            s_t = env.new_game(self.ID, self, opp_agent)\n",
        "\n",
        "            done = False\n",
        "\n",
        "            # iterate until episode is over\n",
        "            while not done:\n",
        "\n",
        "                # choose the action a_t using epsilon greedy (training) policy\n",
        "                a_t = self.e_greedy_policy(s_t, epsilon)\n",
        "\n",
        "                #print(f\"Q-learning agent is at state: {state_to_str(s_t)} and {action_name(a_t)}s (out of {[action_name(x) for x in self.Q[s_t].keys()]})\")\n",
        "\n",
        "                # take the action (a) and observe the outcome state (s') and reward (r)\n",
        "                rewards, new_state, done = env.perform_action(self.ID, a_t, threshhold=threshhold_trainer)\n",
        "\n",
        "                reward = rewards[self.ID-1] * 100\n",
        "\n",
        "                #print(f\"the environment told us that we got a reward of {reward}, that we are now in state {state_to_str(new_state)} and that we {'terminate'if done else 'continue'}\\n\")\n",
        "\n",
        "                # now that we have the reward and the new state we can do the math\n",
        "\n",
        "                self.Q[s_t][a_t] += learning_rate * (reward + self.discount_factor*max(self.Q[new_state].values(), default=0) - self.Q[s_t][a_t])  # if new_state is invalid (can happen in the last state) then it has no available actions and  thus no Q value fo we set it to 0\n",
        "\n",
        "                if done: break\n",
        "\n",
        "                s_t = new_state\n",
        "\n",
        "            #print(f\"=\"*70 + \"\\n\\n\")\n",
        "            self.rewards.append(rewards[self.ID-1])\n",
        "            cumulative_reward += rewards[self.ID-1]\n",
        "            self.cumulative_reward.append(cumulative_reward)\n",
        "        print()\n",
        "        return self.rewards, self.cumulative_reward\n",
        "\n",
        "    def step(self, env:QEnv):\n",
        "        \"\"\"\n",
        "            Perform the action that the current policy suggests for the current state.\n",
        "            Interact with the given environment to get the results of the action.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.policy is None:\n",
        "            self.policy = self.derive_greedy_policy()\n",
        "\n",
        "        a_t = self.policy[self.state]\n",
        "        rewards, new_state, done = env.perform_action(self.ID, a_t)\n",
        "        reward = rewards[self.ID-1] * 100\n",
        "        self.state = new_state\n",
        "\n",
        "    def play_eval_game_vs_random(self, env:QEnv, opponent:RandomAgent):\n",
        "        \"\"\"\n",
        "            Play a game versus the given random agent following the optimal learned policy.\n",
        "        \"\"\"\n",
        "\n",
        "        # if no policy exists, derive one from the current Q table\n",
        "        if self.policy is None:\n",
        "            self.policy = self.derive_greedy_policy()\n",
        "\n",
        "        # draw cards\n",
        "        s_t = env.new_game(self.ID, self, opponent)\n",
        "\n",
        "        done = False\n",
        "\n",
        "        # iterate until the game is over\n",
        "        while not done:\n",
        "\n",
        "            # choose the action a_t using epsilon greedy (training) policy\n",
        "            a_t = self.policy[s_t]\n",
        "\n",
        "            #print(f\"Q-learning agent is at state: {state_to_str(s_t)} and {action_name(a_t)}s (out of {[action_name(x) for x in self.Q[s_t].keys()]})\")\n",
        "\n",
        "            # take the action (a) and observe the outcome state (s') and reward (r)\n",
        "            rewards, new_state, done = env.perform_action(self.ID, a_t)\n",
        "            reward = rewards[self.ID-1]\n",
        "\n",
        "            #print(f\"the environment told us that we got a reward of {reward}, that we are now in state {state_to_str(new_state)} and that we {'terminate'if done else 'continue'}\\n\")\n",
        "\n",
        "            # stop or continue depending on whether the game is over\n",
        "            if done: break\n",
        "            s_t = new_state\n",
        "\n",
        "        #print(f\"=\"*30 + f\"reward: {reward}\" + \"=\"*30 + \"\\n\\n\")\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def play_eval_game_vs_threshold(self, env:QEnv, opponent:ThresholdAgent):\n",
        "        \"\"\"\n",
        "            Play a game versus the given random agent following the optimal learned policy.\n",
        "        \"\"\"\n",
        "\n",
        "        # if no policy exists, derive one from the current Q table\n",
        "        if self.policy is None:\n",
        "            self.policy = self.derive_greedy_policy()\n",
        "\n",
        "        #print(\"Running new game vs threshold opponent:\")\n",
        "\n",
        "        # draw cards\n",
        "        s_t = env.new_game(self.ID, self, opponent)\n",
        "\n",
        "        done = False\n",
        "\n",
        "        # iterate until the game is over\n",
        "        while not done:\n",
        "\n",
        "            # choose the action a_t using epsilon greedy (training) policy\n",
        "            a_t = self.policy[s_t]\n",
        "\n",
        "            #print(f\"Q-learning agent is at state: {state_to_str(s_t)} and {action_name(a_t)}s (out of {[action_name(x) for x in self.Q[s_t].keys()]})\")\n",
        "\n",
        "            # take the action (a) and observe the outcome state (s') and reward (r)\n",
        "            rewards, new_state, done = env.perform_action(self.ID, a_t, threshhold=True)\n",
        "            reward = rewards[self.ID-1]\n",
        "\n",
        "            #print(f\"the environment told us that we got a reward of {reward}, that we are now in state {state_to_str(new_state)} and that we {'terminate'if done else 'continue'}\\n\")\n",
        "\n",
        "            # stop or continue depending on whether the game is over\n",
        "            if done: break\n",
        "            s_t = new_state\n",
        "\n",
        "        #print(f\"=\"*30 + f\"reward: {reward}\" + \"=\"*30 + \"\\n\\n\")\n",
        "\n",
        "        return reward"
      ],
      "metadata": {
        "id": "bFnjx8WP4sXS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Finally conduct the experiments"
      ],
      "metadata": {
        "id": "UNg1QI0H4yCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  discount_factor = 0.75\n",
        "\n",
        "  training_episodes = 10_000     # if increase also decrease α\n",
        "  eval_games = 10_000\n",
        "\n",
        "  # get environment ingredients\n",
        "  start_time = time.time()\n",
        "  (suits, ranks, non_card_state_fields, non_card_state_fields_arrangements,\n",
        "  player_id_i, round_i, own_chips_i, opp_chips_i,\n",
        "  non_card_fields_legality, actions) = create_default_env()\n",
        "  end_time = time.time()\n",
        "\n",
        "  ingr_time = end_time - start_time\n",
        "  print(f\"Preparing the environment took {round(ingr_time*1000, 2)} msec.\")\n",
        "\n",
        "  # create environment\n",
        "  start_time = time.time()\n",
        "  environ = QEnv(suits, ranks, non_card_state_fields, non_card_fields_legality, actions, player_id_i, round_i, own_chips_i, opp_chips_i)\n",
        "  end_time = time.time()\n",
        "\n",
        "  init_time = end_time - start_time\n",
        "  print(f\"Creating the environment took {round(init_time, 2)} sec.\")\n",
        "\n",
        "  # create the agent\n",
        "  start_time = time.time()\n",
        "\n",
        "  q_learning_agent_t = QLearningAgent(1, environ, 0.01, discount_factor)\n",
        "  q_learning_agent_r = QLearningAgent(1, environ, 0.01, discount_factor)\n",
        "  end_time = time.time()\n",
        "  agent_init_time = end_time - start_time\n",
        "  print(f\"Creating the agent took {round(agent_init_time, 2)} sec.\")\n",
        "\n",
        "  # create a dummy opponent (just to hold the chips)\n",
        "  dummy_opp = RandomAgent(2)\n",
        "  dummy_opp_thresh = ThresholdAgent(2)\n",
        "\n",
        "  # train the agent using a random agent as part of the environment\n",
        "  start_time = time.time()\n",
        "  q_learning_agent_t.train(training_episodes, environ, dummy_opp_thresh, threshhold_trainer=True)\n",
        "  q_learning_agent_r.train(training_episodes, environ, dummy_opp, threshhold_trainer=False)\n",
        "  end_time = time.time()\n",
        "  training_time = end_time - start_time\n",
        "  print(f\"training took {round(training_time, 2)} sec.\")\n",
        "\n",
        "  # derive a policy from the Q table\n",
        "  q_learning_agent_t.policy = q_learning_agent_t.derive_greedy_policy()\n",
        "  q_learning_agent_r.policy = q_learning_agent_r.derive_greedy_policy()\n",
        "\n",
        "  # run evaluation games to see how good the learned policy is\n",
        "  eval_cumulative_reward_t = 0\n",
        "  eval_cumulative_rewards_t = []\n",
        "  for i in range(eval_games):\n",
        "      print(f\"\\rRunning evaluation episode {i}\", end=\"\", flush=True)\n",
        "      eval_cumulative_reward_t += q_learning_agent_t.play_eval_game_vs_random(environ, dummy_opp)\n",
        "      eval_cumulative_rewards_t.append(eval_cumulative_reward_t)\n",
        "\n",
        "  # run evaluation games to see how good the learned policy is\n",
        "  eval_cumulative_reward_r = 0\n",
        "  eval_cumulative_rewards_r = []\n",
        "  for i in range(eval_games):\n",
        "      print(f\"\\rRunning evaluation episode {i}\", end=\"\", flush=True)\n",
        "      eval_cumulative_reward_r += q_learning_agent_t.play_eval_game_vs_random(environ, dummy_opp)\n",
        "      eval_cumulative_rewards_r.append(eval_cumulative_reward_r)\n",
        "\n",
        "  print()\n",
        "\n",
        "  # plot the evaluation reward\n",
        "  plt.figure()\n",
        "  t = np.arange(len(eval_cumulative_rewards_t))\n",
        "  plt.title(\"Cumulative Evaluation Reward\")\n",
        "  plt.plot(t, eval_cumulative_rewards_t, label=f'Trained on threshold agent')\n",
        "  plt.plot(t, eval_cumulative_rewards_r, label=f'Trained on random agent')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  plt.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "VEs-haNt4wPc",
        "outputId": "11833a38-2641-47c1-dc20-d766b9acee70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing the environment took 7.92 msec.\n",
            "Creating the environment took 5.16 sec.\n",
            "Creating the agent took 29.89 sec.\n",
            "Running training episode 9999\n",
            "Running training episode 9999\n",
            "training took 13.27 sec.\n",
            "Running evaluation episode 9999\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}